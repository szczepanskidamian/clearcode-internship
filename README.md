# Internship tasks

I prepared simple web_crawler and csv_report_processing reqruitment tasks for ClearCode S.A.

I wrote my scipts on basis of the examples (simple http server for web crawler and input data for csv report).

The reason why requirements.txt contains so many libraries is simple - I used conda interpreter and all of those 
modules are built-in, but in fact I was using only few of them (urllib, sys, re, datetime, csv, pycountry and 
operator).

I tried to make these scripts as readable and optimized as I possibly can, but still I'm pretty sure it's far 
from perfection.

I would be delighted to receive opportunity to gain priceless expierience.

